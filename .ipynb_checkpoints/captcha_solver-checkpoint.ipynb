{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3caa644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  1\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "578579"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def captcha_solver(address):\n",
    "    filenames = []\n",
    "    for dirname, _, files in os.walk(address):\n",
    "        for f in files:\n",
    "            filenames = np.append(filenames, f)\n",
    "\n",
    "    num_samples = len(filenames)\n",
    "    print('number of samples: ', num_samples)\n",
    "\n",
    "    char_list = \"0123456789\"\n",
    "\n",
    "\n",
    "    def encode_to_labels(txt):\n",
    "        # encoding each label into list of digits\n",
    "        encoded_list = []\n",
    "        for char in txt:\n",
    "            encoded_list.append(char_list.index(char))\n",
    "\n",
    "        return encoded_list\n",
    "\n",
    "\n",
    "    path = r'D:/hiweb/exports/temp/'\n",
    "\n",
    "    # lists for training dataset\n",
    "    training_img = []  # the images for training the model\n",
    "    training_txt = []  # the labels\n",
    "    train_input_length = []  # the input of LSTM part of the model\n",
    "    train_label_length = []  # the label's length (4 to 7)\n",
    "    train_orig_txt = []\n",
    "\n",
    "    # lists for validation dataset\n",
    "    valid_img = []\n",
    "    valid_txt = []\n",
    "    valid_input_length = []\n",
    "    valid_label_length = []\n",
    "    valid_orig_txt = []\n",
    "\n",
    "    max_label_len = 0  # max length for our labels (in this case 7)\n",
    "\n",
    "    for file in filenames:\n",
    "        raw = Image.open(path + file)\n",
    "        gray = ImageOps.grayscale(raw)\n",
    "        img = np.array(gray)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = img / 255.\n",
    "\n",
    "        txt = file.split('.')[0]\n",
    "\n",
    "        if len(txt) > max_label_len:\n",
    "            max_label_len = len(txt)\n",
    "\n",
    "        # split the dataset (85% train, 15% test)\n",
    "        if np.random.rand() >= 0:\n",
    "            valid_orig_txt.append(txt)\n",
    "            valid_label_length.append(len(txt))\n",
    "            valid_input_length.append(75)\n",
    "            valid_img.append(img)\n",
    "            valid_txt.append(encode_to_labels(txt))\n",
    "        else:\n",
    "            train_orig_txt.append(txt)\n",
    "            train_label_length.append(len(txt))\n",
    "            train_input_length.append(75)\n",
    "            training_img.append(img)\n",
    "            training_txt.append(encode_to_labels(txt))\n",
    "\n",
    "    train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value=len(char_list))\n",
    "    valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value=len(char_list))\n",
    "\n",
    "\n",
    "    def ctc_lambda_func(args):\n",
    "        y_pred, labels, input_length, label_length = args\n",
    "\n",
    "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "    training_img = np.array(training_img)\n",
    "    train_input_length = np.array(train_input_length)\n",
    "    train_label_length = np.array(train_label_length)\n",
    "\n",
    "    valid_img = np.array(valid_img)\n",
    "    valid_input_length = np.array(valid_input_length)\n",
    "    valid_label_length = np.array(valid_label_length)\n",
    "\n",
    "    training_txt = np.array(training_txt)\n",
    "    valid_txt = np.array(valid_txt)\n",
    "\n",
    "    inputs = Input(shape=(64, 306, 1))\n",
    "\n",
    "    conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_2)\n",
    "    conv_4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv_3)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    "\n",
    "    conv_5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool_4)\n",
    "    batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "    conv_6 = Conv2D(512, (3, 3), activation='relu', padding='same')(batch_norm_5)\n",
    "    batch_norm_6 = BatchNormalization()(conv_6)\n",
    "    pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "\n",
    "    conv_7 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool_6)\n",
    "    batch_norm_7 = BatchNormalization()(conv_7)\n",
    "    pool_7 = MaxPool2D(pool_size=(2, 1))(batch_norm_7)\n",
    "\n",
    "    conv_8 = Conv2D(512, (2, 2), activation='relu')(pool_7)\n",
    "\n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_8)\n",
    "\n",
    "    blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(squeezed)\n",
    "    blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)\n",
    "\n",
    "    outputs = Dense(len(char_list) + 1, activation='softmax')(blstm_2)\n",
    "    prediction_model = Model(inputs, outputs)\n",
    "    # load the model weights\n",
    "    prediction_model.load_weights('D:\\hiweb\\model_weights_V1_1413data.hdf5')\n",
    "\n",
    "    # predict outputs on validation images\n",
    "    prediction = prediction_model.predict(valid_img[:20])\n",
    "\n",
    "    # use CTC decoder\n",
    "    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "    # see the results\n",
    "    i = 0\n",
    "    pred = ''\n",
    "    for x in out:\n",
    "    #     print(\"original_text =  \", valid_orig_txt[i])\n",
    "    #     print(\"predicted text = \", end='')\n",
    "        for p in x:\n",
    "            if int(p) != -1:\n",
    "\n",
    "                pred += str(p)\n",
    "    #             print(char_list[int(p)], end='')\n",
    "        print('\\n')\n",
    "        i += 1\n",
    "    return(int(pred))\n",
    "\n",
    "captcha_solver('D:/hiweb/exports/temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c7547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
